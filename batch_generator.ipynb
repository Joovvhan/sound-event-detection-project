{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import queue\n",
    "import librosa\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import threading\n",
    "\n",
    "import scipy.signal as scipy_signal\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, metadata_path, class_name_to_class_idx_dict):\n",
    "        \n",
    "        self.queue = queue.Queue(maxsize=10)\n",
    "        self.batch_size = 64\n",
    "\n",
    "        self.fs = 44100 / 2\n",
    "\n",
    "        self.nsc_in_ms = 40\n",
    "        self.nov_in_ms = 0\n",
    "        self.nsc_in_sample = int(self.nsc_in_ms / 1000 * self.fs)\n",
    "        self.nov_in_sample = int(self.nov_in_ms / 1000 * self.fs)\n",
    "\n",
    "        self.num_mels = 160\n",
    "\n",
    "        self.mel_band = librosa.filters.mel(self.fs, self.nsc_in_sample, n_mels=self.num_mels)\n",
    "\n",
    "        self.batch_flag = None\n",
    "        \n",
    "        with open(metadata_path) as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "\n",
    "            metadata = np.array(list(csv_reader))\n",
    "            self.file_names = metadata[:, 0]\n",
    "            self.durations = np.asarray(list(map(float, metadata[:, 1])))\n",
    "            \n",
    "        self.class_name_to_class_idx_dict = class_name_to_class_idx_dict\n",
    "          \n",
    "    def shuffle_dataset(self):\n",
    "        \n",
    "        sorted_idx = np.argsort(self.durations)\n",
    "        self.file_names = self.file_names[sorted_idx]\n",
    "        self.durations = self.durations[sorted_idx]\n",
    "        \n",
    "#         random_idx = np.random.permutation(len(self.file_names))\n",
    "#         self.file_names = self.file_names[random_idx]\n",
    "#         self.durations = self.durations[random_idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def start_loading(self):\n",
    "        \n",
    "        t = threading.Thread(target=self.batching_thread)\n",
    "        t.start()\n",
    "#         t.join()\n",
    "        \n",
    "    def batch_generator(self):\n",
    "        \n",
    "        self.batch_flag = True\n",
    "        self.start_loading()\n",
    "        \n",
    "        while self.batch_flag or not self.queue.empty():\n",
    "            try:\n",
    "                yield self.queue.get(timeout=1)\n",
    "            except queue.Empty:\n",
    "                print('Empty Queue Found')\n",
    "                time.sleep(1)\n",
    "        \n",
    "    def batching_thread(self):\n",
    "        \n",
    "        mel_buffer_list = list()\n",
    "        label_buffer_list = list()\n",
    "        \n",
    "        test_buffer_list = list()\n",
    "        \n",
    "        for file_name in self.file_names:\n",
    "            mel = self.wav_path_to_mel(file_name)\n",
    "            class_label = file_name.split('/')[1]\n",
    "            class_idx = self.class_name_to_class_idx_dict[class_label]\n",
    "#             test_buffer_list.append(file_name)\n",
    "            mel_buffer_list.append(mel)\n",
    "            label_buffer_list.append(class_idx)\n",
    "    \n",
    "            if len(mel_buffer_list) == self.batch_size:\n",
    "                batch = self.pack_batch(mel_buffer_list, label_buffer_list)\n",
    "                self.queue.put(batch)\n",
    "\n",
    "                mel_buffer_list = list()\n",
    "                label_buffer_list = list()\n",
    "\n",
    "        if len(mel_buffer_list) > 0:\n",
    "            batch = self.pack_batch(mel_buffer_list, label_buffer_list)\n",
    "            self.queue.put(batch)\n",
    "\n",
    "            mel_buffer_list = list()\n",
    "            label_buffer_list = list()\n",
    "                \n",
    "        self.batch_flag = False\n",
    "        \n",
    "    def wav_path_to_mel(self, wav_path):\n",
    "\n",
    "        data, fs = librosa.core.load(wav_path, sr=None)\n",
    "\n",
    "        f, t, Zxx = scipy_signal.stft(data, fs=fs, \n",
    "                                      nperseg=self.nsc_in_sample,\n",
    "                                      noverlap=self.nov_in_sample)\n",
    "\n",
    "        Sxx = np.abs(Zxx)\n",
    "        Sxx = np.matmul(self.mel_band, Sxx)\n",
    "        normalized_spectrogram = (20 * np.log10(np.maximum(Sxx, 1e-8)) + 160) / 160\n",
    "\n",
    "#         if self.is_train:\n",
    "#             normalized_spectrogram += (np.random.random(normalized_spectrogram.shape) - 0.5)/10\n",
    "#             normalized_spectrogram = np.clip(normalized_spectrogram, 0, None)\n",
    "        \n",
    "        return normalized_spectrogram\n",
    "    \n",
    "    def pack_batch(self, mels, labels):\n",
    "        \n",
    "        # TODO\n",
    "        \n",
    "        # mels (B, F, T)\n",
    "        \n",
    "        batch_size = len(mels) # B\n",
    "        num_mels = self.num_mels # F\n",
    "        max_time_step = np.max([mel.shape[1] for mel in mels]) # T\n",
    "        \n",
    "        x = np.zeros([batch_size, num_mels, max_time_step])\n",
    "        \n",
    "        for i, mel in enumerate(mels):\n",
    "            x[i, :, -mel.shape[1]:] = mel\n",
    "            \n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(labels)\n",
    "        \n",
    "        return (x, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir('train')\n",
    "classes.sort()\n",
    "\n",
    "class_name_to_class_idx_dict = {class_name: i for i, class_name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader('train_metadata.csv', class_name_to_class_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader.shuffle_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader.start_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = train_dataloader.batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIME: 2020-02-13 14:56:44.765798] [SHAPE: torch.Size([64, 160, 14])] \n",
      "[TIME: 2020-02-13 14:56:44.802988] [SHAPE: torch.Size([64, 160, 14])] \n",
      "[TIME: 2020-02-13 14:56:44.838573] [SHAPE: torch.Size([64, 160, 14])] \n",
      "[TIME: 2020-02-13 14:56:44.876701] [SHAPE: torch.Size([64, 160, 16])] \n",
      "[TIME: 2020-02-13 14:56:44.918466] [SHAPE: torch.Size([64, 160, 18])] \n",
      "[TIME: 2020-02-13 14:56:44.960463] [SHAPE: torch.Size([64, 160, 20])] \n",
      "[TIME: 2020-02-13 14:56:45.008338] [SHAPE: torch.Size([64, 160, 22])] \n",
      "[TIME: 2020-02-13 14:56:45.055209] [SHAPE: torch.Size([64, 160, 24])] \n",
      "[TIME: 2020-02-13 14:56:45.111652] [SHAPE: torch.Size([64, 160, 26])] \n",
      "[TIME: 2020-02-13 14:56:45.159095] [SHAPE: torch.Size([64, 160, 27])] \n",
      "[TIME: 2020-02-13 14:56:45.212599] [SHAPE: torch.Size([64, 160, 29])] \n",
      "[TIME: 2020-02-13 14:56:45.272070] [SHAPE: torch.Size([64, 160, 31])] \n",
      "[TIME: 2020-02-13 14:56:45.326519] [SHAPE: torch.Size([64, 160, 32])] \n",
      "[TIME: 2020-02-13 14:56:45.381926] [SHAPE: torch.Size([64, 160, 35])] \n",
      "[TIME: 2020-02-13 14:56:45.440413] [SHAPE: torch.Size([64, 160, 37])] \n",
      "[TIME: 2020-02-13 14:56:45.497826] [SHAPE: torch.Size([64, 160, 40])] \n",
      "[TIME: 2020-02-13 14:56:45.553403] [SHAPE: torch.Size([64, 160, 43])] \n",
      "[TIME: 2020-02-13 14:56:45.617089] [SHAPE: torch.Size([64, 160, 46])] \n",
      "[TIME: 2020-02-13 14:56:45.683991] [SHAPE: torch.Size([64, 160, 49])] \n",
      "[TIME: 2020-02-13 14:56:45.748945] [SHAPE: torch.Size([64, 160, 51])] \n",
      "[TIME: 2020-02-13 14:56:45.813770] [SHAPE: torch.Size([64, 160, 55])] \n",
      "[TIME: 2020-02-13 14:56:45.881907] [SHAPE: torch.Size([64, 160, 60])] \n",
      "[TIME: 2020-02-13 14:56:45.966579] [SHAPE: torch.Size([64, 160, 64])] \n",
      "[TIME: 2020-02-13 14:56:46.046760] [SHAPE: torch.Size([64, 160, 67])] \n",
      "[TIME: 2020-02-13 14:56:46.132594] [SHAPE: torch.Size([64, 160, 70])] \n",
      "[TIME: 2020-02-13 14:56:46.225575] [SHAPE: torch.Size([64, 160, 75])] \n",
      "[TIME: 2020-02-13 14:56:46.311875] [SHAPE: torch.Size([64, 160, 81])] \n",
      "[TIME: 2020-02-13 14:56:46.403543] [SHAPE: torch.Size([64, 160, 87])] \n",
      "[TIME: 2020-02-13 14:56:46.520305] [SHAPE: torch.Size([64, 160, 95])] \n",
      "[TIME: 2020-02-13 14:56:46.637477] [SHAPE: torch.Size([64, 160, 103])] \n",
      "[TIME: 2020-02-13 14:56:46.759004] [SHAPE: torch.Size([64, 160, 113])] \n",
      "[TIME: 2020-02-13 14:56:46.892481] [SHAPE: torch.Size([64, 160, 123])] \n",
      "[TIME: 2020-02-13 14:56:47.057576] [SHAPE: torch.Size([64, 160, 134])] \n",
      "[TIME: 2020-02-13 14:56:47.215064] [SHAPE: torch.Size([64, 160, 148])] \n",
      "[TIME: 2020-02-13 14:56:47.402268] [SHAPE: torch.Size([64, 160, 163])] \n",
      "[TIME: 2020-02-13 14:56:47.603511] [SHAPE: torch.Size([64, 160, 181])] \n",
      "[TIME: 2020-02-13 14:56:47.852193] [SHAPE: torch.Size([64, 160, 203])] \n",
      "[TIME: 2020-02-13 14:56:48.135125] [SHAPE: torch.Size([64, 160, 230])] \n",
      "[TIME: 2020-02-13 14:56:48.434092] [SHAPE: torch.Size([64, 160, 254])] \n",
      "[TIME: 2020-02-13 14:56:48.813058] [SHAPE: torch.Size([64, 160, 312])] \n",
      "[TIME: 2020-02-13 14:56:49.316149] [SHAPE: torch.Size([64, 160, 392])] \n",
      "[TIME: 2020-02-13 14:56:49.996592] [SHAPE: torch.Size([64, 160, 498])] \n",
      "[TIME: 2020-02-13 14:56:50.508803] [SHAPE: torch.Size([64, 160, 501])] \n",
      "[TIME: 2020-02-13 14:56:50.970443] [SHAPE: torch.Size([64, 160, 501])] \n",
      "[TIME: 2020-02-13 14:56:51.305904] [SHAPE: torch.Size([49, 160, 501])] \n"
     ]
    }
   ],
   "source": [
    "for batch in batch_generator:\n",
    "    print('[TIME: {}] [SHAPE: {}] '.format(datetime.datetime.now(), batch[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
